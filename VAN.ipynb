{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br_cXSZDsqB6"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.metrics import f1_score\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"pd_speech_features.csv\")\n",
        "\n",
        "y = df.loc[:,'class']\n",
        "X = df.drop(['class', 'id'], axis=1)\n",
        "X = X.values\n",
        "y = y.values\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X = min_max_scaler.fit_transform(X)\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "X, y = sm.fit_resample(X, y)\n",
        "\n",
        "oversampled = np.column_stack((X, y))\n",
        "num_ones = np.count_nonzero(oversampled[:, -1] == 1)\n",
        "print(\"number of PD:\", num_ones)\n",
        "print(\"number of non-PD:\", oversampled.shape[0]-num_ones)"
      ],
      "metadata": {
        "id": "2l4rSXtkstnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f6b3bc7-3970-422c-c154-843c6365c79f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of PD: 564\n",
            "number of non-PD: 564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Iris dataset\n",
        "# y = df.loc[:,'class']\n",
        "# X = df.drop(['class', 'id'], axis=1)\n",
        "# X = X.values\n",
        "# y = y.values\n",
        "\n",
        "# X = (X - X.min()) / (X.max() - X.min())\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# Define the VAE encoder model\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.latent_dim = latent_dim\n",
        "    self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "    self.fc2 = nn.Linear(hidden_dim, latent_dim)\n",
        "    self.fc3 = nn.Linear(hidden_dim, latent_dim)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = torch.relu(x)\n",
        "    mu = self.fc2(x)\n",
        "    log_var = self.fc3(x)\n",
        "    return mu, log_var\n",
        "\n",
        "# Define the VAE decoder model\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, latent_dim, hidden_dim, output_dim):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.fc1 = nn.Linear(latent_dim, hidden_dim)\n",
        "    self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "  \n",
        "  def forward(self, z):\n",
        "    z = self.fc1(z)\n",
        "    z = torch.relu(z)\n",
        "    x_hat = self.fc2(z)\n",
        "    return x_hat\n",
        "\n",
        "# Define the VAE model\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super(VAE, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "  \n",
        "  def forward(self, x):\n",
        "    mu, log_var = self.encoder(x)\n",
        "    std = torch.exp(0.5 * log_var)\n",
        "    eps = torch.randn_like(std)\n",
        "    z = mu + eps * std\n",
        "    x_hat = self.decoder(z)\n",
        "    return x_hat, mu, log_var\n",
        "\n",
        "def kl_loss(mu, log_var):\n",
        "  kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "  return kl_loss\n",
        "\n",
        "encoder = Encoder(753, 400, 120)\n",
        "decoder = Decoder(120, 400, 753)\n",
        "\n",
        "# Define the VAE model\n",
        "vae = VAE(encoder, decoder)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10):\n",
        "  for i, x in enumerate(X):\n",
        "    # Pass the data through the VAE model\n",
        "    x_hat, mu, log_var = vae(x)\n",
        "    \n",
        "    # Compute the loss\n",
        "    reconstruction_loss = nn.MSELoss()(x_hat, x)\n",
        "    kl_loss_val = kl_loss(mu, log_var)\n",
        "    loss = reconstruction_loss + kl_loss_val\n",
        "    \n",
        "    # Update the model parameters\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "  # Print the loss at the end of each epoch\n",
        "  print(f'Epoch {epoch}: Loss {loss.item()}')"
      ],
      "metadata": {
        "id": "K_9UOPPHszyq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e52b962-b42c-4d85-ec79-5a8dfa222942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss 0.015139072202146053\n",
            "Epoch 1: Loss 0.008036714047193527\n",
            "Epoch 2: Loss 0.0205801110714674\n",
            "Epoch 3: Loss 0.008711128495633602\n",
            "Epoch 4: Loss 0.0054746633395552635\n",
            "Epoch 5: Loss 0.007398189976811409\n",
            "Epoch 6: Loss 0.006864612456411123\n",
            "Epoch 7: Loss 0.0059611680917441845\n",
            "Epoch 8: Loss 0.005072538275271654\n",
            "Epoch 9: Loss 0.005561823956668377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df.loc[:,'class']\n",
        "X = df.drop(['class', 'id'], axis=1)\n",
        "X = X.values\n",
        "y = y.values\n",
        "\n",
        "X = (X - X.min()) / (X.max() - X.min())\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float)\n",
        "# y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "vae = VAE(encoder, decoder)\n",
        "mu, log_var = vae.encoder(X)\n",
        "\n",
        "X = mu.detach().numpy() \n",
        "log_var_np = log_var.detach().numpy()\n",
        "\n",
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YATxdBnztHiq",
        "outputId": "b16d454b-b64d-4f4a-f680-f180fc364386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(756, 120)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiEIh6oJgVV4",
        "outputId": "67426705-7ae9-4a1b-8299-3b31ab6d4348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(567, 120)\n",
            "(189, 120)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_func(X_train, y_train, X_test, y_test, X, y):\n",
        "    model = LogisticRegression(random_state=42, max_iter=1000).fit(X_train, y_train)\n",
        "    # fitting the classifier\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_train = model.predict(X_train)\n",
        "\n",
        "    print(\"--------------------------------------------------------\")\n",
        "    print(\"Test Accuracy LogisticRegression Model :\",  accuracy_score(y_test, y_pred))\n",
        "    print(\"--------------------------------------------------------\")\n",
        "    score = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
        "    print(\"Cross valdation avaerage score\", score.mean())\n",
        "    print(\"--------------------------------------------------------\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    # confusion_mtx = confusion_matrix(y_test, y_pred)\n",
        "    # plot_confusion_matrix(confusion_mtx)\n",
        "\n",
        "\n",
        "lr_func(X_train, y_train, X_test, y_test, X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFJ4k2DGtRK0",
        "outputId": "8d4c0e6f-1ce3-4792-c6d7-494cd79e81f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------\n",
            "Test Accuracy LogisticRegression Model : 0.7301587301587301\n",
            "--------------------------------------------------------\n",
            "Cross valdation avaerage score 0.7460352039037993\n",
            "--------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        51\n",
            "           1       0.73      1.00      0.84       138\n",
            "\n",
            "    accuracy                           0.73       189\n",
            "   macro avg       0.37      0.50      0.42       189\n",
            "weighted avg       0.53      0.73      0.62       189\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_func_poly(X_train, y_train, X_test, y_test, X, y): #X and y are needed to calculate cross validation score\n",
        "\n",
        "    model = SVC(kernel='poly', decision_function_shape='ovr')\n",
        "    model.fit(X_train, y_train)\n",
        "    #‘linear’, ‘poly’, ‘rbf’\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_train = model.predict(X_train)\n",
        "\n",
        "    print(\"--------------------------------------------------------\")\n",
        "    print(\"Test Accuracy LogisticRegression Model :\",  accuracy_score(y_test, y_pred))\n",
        "    print(\"--------------------------------------------------------\")\n",
        "    score = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
        "    print(\"Cross valdation avaerage score\", score.mean())\n",
        "    print(\"--------------------------------------------------------\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    # confusion_mtx = confusion_matrix(y_test, y_pred)\n",
        "    # plot_confusion_matrix(confusion_mtx)\n",
        "\n",
        "svm_func_poly(X_train, y_train, X_test, y_test, X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhhLUZ1E00ph",
        "outputId": "16591d7f-1c30-47c6-92ef-3e5974c0fdb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------\n",
            "Test Accuracy LogisticRegression Model : 0.7301587301587301\n",
            "--------------------------------------------------------\n",
            "Cross valdation avaerage score 0.7460352039037993\n",
            "--------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        51\n",
            "           1       0.73      1.00      0.84       138\n",
            "\n",
            "    accuracy                           0.73       189\n",
            "   macro avg       0.37      0.50      0.42       189\n",
            "weighted avg       0.53      0.73      0.62       189\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}